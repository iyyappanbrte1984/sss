<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <title>Fish vs Trash - Phone → micro:bit</title>
  <meta name="viewport" content="width=device-width,initial-scale=1.0">
  <style>
    body { font-family: Arial, sans-serif; padding: 12px; }
    video { border: 1px solid #ccc; border-radius: 8px; }
    button { margin:6px; padding:8px 12px; font-size:16px; }
    #status { margin-top:6px; font-weight:600; }
  </style>
</head>
<body>
  <h1>Fish vs Trash — Vision Demo</h1>
  <video id="webcam" autoplay playsinline width="320" height="240"></video>
  <div>
    <button id="btnStart">Start Camera & Load Model</button>
    <button id="btnConnect">Connect micro:bit</button>
  </div>
  <div id="status">Status: idle</div>
  <div id="label">Label: --</div>

    <!-- Use explicit compatible versions -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.21.0/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8.4/dist/teachablemachine-image.min.js"></script>


  <script>
  // ===== CONFIG: only change MODEL_PATH if necessary =====
  const MODEL_PATH = "model/model.json"; // default when you upload to GitHub Pages
  const CLASS_NAMES = null; // set to null to auto-read metadata.json labels, otherwise e.g. ['Fish','Trash']

  // BLE UART UUIDs
  const UART_SERVICE_UUID  = '6e400001-b5a3-f393-e0a9-e50e24dcca9e';
  const UART_TX_CHAR_UUID  = '6e400002-b5a3-f393-e0a9-e50e24dcca9e'; // write

  let model = null;
  let video = document.getElementById('webcam');
  let btnStart = document.getElementById('btnStart');
  let btnConnect = document.getElementById('btnConnect');
  let statusEl = document.getElementById('status');
  let labelEl = document.getElementById('label');

  let uartTxChar = null;
  let classNames = CLASS_NAMES; // array of labels (string)

  async function loadModelAndLabels() {
    statusEl.innerText = 'Status: loading model...';
    model = await tf.loadGraphModel(MODEL_PATH);
    statusEl.innerText = 'Status: model loaded';
    if (!classNames) {
      try {
        const metaResp = await fetch(MODEL_PATH.replace('model.json','metadata.json'));
        if (metaResp.ok) {
          const meta = await metaResp.json();
          if (meta.labels) classNames = meta.labels;
        }
      } catch(e) { console.warn('metadata.json not found or unreadable'); }
    }
    if (!classNames) classNames = ['Fish','Trash']; // fallback: ensure something
    console.log('Class names:', classNames);
  }

  async function startCamera() {
    statusEl.innerText = 'Status: starting camera...';
    const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' }, audio: false });
    video.srcObject = stream;
    await video.play();
    statusEl.innerText = 'Status: camera started';
    requestAnimationFrame(classifyLoop);
  }

  async function classifyLoop() {
    if (!model || video.readyState !== 4) {
      requestAnimationFrame(classifyLoop);
      return;
    }
    // typical Teachable Machine exports expect 224x224 input
    const inputSize = 224;
    const t = tf.browser.fromPixels(video).resizeNearestNeighbor([inputSize,inputSize]).toFloat().div(255.0).expandDims();
    const preds = model.predict(t);
    const data = await preds.data();
    t.dispose();
    preds.dispose();

    // pick max
    let maxI = 0;
    for (let i=1;i<data.length;i++) if (data[i] > data[maxI]) maxI = i;
    const conf = Math.round(data[maxI]*100);
    const label = classNames[maxI] || ("Class"+maxI);
    labelEl.innerText = `Label: ${label} (${conf}%)`;
    statusEl.innerText = 'Status: running inference';

    // only send if confident enough (avoid spam) — adjust threshold as needed
    if (uartTxChar && conf >= 50) {
      sendToMicrobit(label.toUpperCase());
    }
    // run at ~2 fps to save battery
    setTimeout(()=>requestAnimationFrame(classifyLoop), 450);
  }

  async function connectMicrobit() {
    try {
      statusEl.innerText = 'Status: requesting device...';
      const device = await navigator.bluetooth.requestDevice({
        filters: [{ namePrefix: 'BBC micro:bit' }],
        optionalServices: [UART_SERVICE_UUID]
      });
      statusEl.innerText = 'Status: connecting...';
      const server = await device.gatt.connect();
      const service = await server.getPrimaryService(UART_SERVICE_UUID);
      uartTxChar = await service.getCharacteristic(UART_TX_CHAR_UUID);
      statusEl.innerText = 'Status: connected to ' + (device.name||'micro:bit');
    } catch (err) {
      console.error(err);
      statusEl.innerText = 'Status: Bluetooth failed';
      alert('Bluetooth/connection failed. Use Chrome on Android and ensure micro:bit has a BLE UART service enabled.');
    }
  }

  async function sendToMicrobit(text) {
    if (!uartTxChar) return;
    const enc = new TextEncoder();
    try {
      await uartTxChar.writeValue(enc.encode(text + '\n'));
      console.log('Sent to micro:bit:', text);
    } catch(e) {
      console.warn('Write failed', e);
      statusEl.innerText = 'Status: write failed';
    }
  }

  btnStart.onclick = async () => {
    try {
      if (!model) await loadModelAndLabels();
      await startCamera();
    } catch(e) {
      console.error(e);
      statusEl.innerText = 'Status: error: ' + e.message;
      alert('Error starting camera or loading model. Check console.');
    }
  };
  btnConnect.onclick = async () => { await connectMicrobit(); };
  </script>
  <!-- BEGIN: Robust camera+model loader (replace previous start code) -->
<div id="errorBox" style="position:fixed;left:8px;right:8px;bottom:8px;padding:10px;background:#fff3cd;border:1px solid #f5c6cb;z-index:9999;font-family:Arial, sans-serif;display:none;">
  <strong>Debug info:</strong>
  <pre id="errorText" style="white-space:pre-wrap;margin:6px 0 0 0;font-size:13px"></pre>
</div>

<script>
  function showError(msg){
    const box = document.getElementById('errorBox');
    const txt = document.getElementById('errorText');
    txt.textContent = (msg && msg.stack) ? (msg.stack) : String(msg);
    box.style.display = 'block';
    console.error('User-visible error:', msg);
  }

  // Update these to match your repo/model path if different
  const MODEL_URL = 'model/model.json';
  const METADATA_URL = 'model/metadata.json';

  // placeholder for the loaded model and webcam
  let tmModel = null;
  let webcamStream = null;
  let videoEl = null;

  async function initApp() {
    try {
      // check model files exist (fetch test)
      const r = await fetch(MODEL_URL, { method: 'GET' });
      if (!r.ok) throw new Error('Model file not found at ' + MODEL_URL + ' (HTTP ' + r.status + ')');

      // load teachable machine image model
      tmModel = await tmImage.load(MODEL_URL, METADATA_URL);
      if (!tmModel) throw new Error('tmImage.load returned undefined (version mismatch?)');

      // start camera
      videoEl = document.querySelector('video') || document.createElement('video');
      videoEl.setAttribute('autoplay','');
      videoEl.setAttribute('playsinline',''); // for mobile
      videoEl.style.width = '320px';
      videoEl.style.height = '240px';
      if (!document.querySelector('video')) document.body.insertBefore(videoEl, document.body.firstChild);

      try {
        webcamStream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' }, audio: false });
        videoEl.srcObject = webcamStream;
        await videoEl.play();
      } catch(camErr) {
        throw new Error('Camera start failed: ' + (camErr && camErr.message ? camErr.message : camErr));
      }

      // At this point model + camera are running
      // Optionally start prediction loop
      startPredictionLoop();

    } catch (err) {
      showError(err);
    }
  }

  async function startPredictionLoop() {
    try {
      if (!tmModel) throw new Error('Model not loaded');
      if (!videoEl || videoEl.readyState < 2) {
        // wait for video to be ready
        await new Promise(res => setTimeout(res, 500));
      }
      // do a single predict as a test
      const prediction = await tmModel.predict(videoEl);
      // prediction should be an array of objects if model loaded correctly
      if (!Array.isArray(prediction)) throw new Error('Predict returned unexpected result: ' + JSON.stringify(prediction));
      console.log('Single predict OK:', prediction);
      // update any UI label if present
      const labelEl = document.getElementById('label') || (function(){ let e=document.createElement('div'); e.id='label'; document.body.appendChild(e); return e; })();
      labelEl.textContent = 'Label: ' + (prediction[0] && prediction[0].className ? prediction[0].className : '--');
      // start continuous loop
      requestAnimationFrame(predictLoop);
    } catch(e) {
      showError(e);
    }
  }

  async function predictLoop() {
    try {
      const preds = await tmModel.predict(videoEl);
      // handle the predictions as you already do
      // example: display top label
      preds.sort((a,b)=>b.probability - a.probability);
      const top = preds[0];
      const labelEl = document.getElementById('label');
      if (labelEl) labelEl.textContent = 'Label: ' + top.className + ' (' + (top.probability*100).toFixed(1) + '%)';
    } catch(loopErr) {
      showError(loopErr);
      return;
    }
    setTimeout(()=>requestAnimationFrame(predictLoop), 300); // ~3 FPS
  }

  // bind to the "Start Camera & Load Model" button if present
  window.addEventListener('load', () => {
    const btn = document.querySelector('button#startBtn') || document.querySelector('button');
    if (btn) btn.addEventListener('click', initApp);
    // Optionally auto-start:
    // initApp();
  });
</script>
<!-- END: Robust camera+model loader -->

</body>
</html>
